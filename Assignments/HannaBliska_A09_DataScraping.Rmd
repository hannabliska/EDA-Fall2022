---
title: "Assignment 09: Data Scraping"
author: "Hanna Bliska"
output: pdf_document
geometry: margin=2.54cm
editor_options: 
  chunk_output_type: console
---

## OVERVIEW

This exercise accompanies the lessons in Environmental Data Analytics on data scraping. 

## Directions
1. Rename this file `<FirstLast>_A09_DataScraping.Rmd` (replacing `<FirstLast>` with your first and last name).
2. Change "Student Name" on line 3 (above) with your name.
3. Work through the steps, **creating code and output** that fulfill each instruction.
4. Be sure to **answer the questions** in this assignment document.
5. When you have completed the assignment, **Knit** the text and code into a single PDF file.


## Set up 
1. Set up your session:

* Check your working directory
* Load the packages `tidyverse`, `rvest`, and any others you end up using.
* Set your ggplot theme

```{r, message = FALSE}
#1
getwd()
library(tidyverse)
library(lubridate)
library(rvest)
library(scales)

mytheme <- theme_classic(base_size = 12) + theme(
  axis.text = element_text(color="black"), 
  legend.position = "right") #creating a theme

theme_set(mytheme) #setting my theme
```

2. We will be scraping data from the NC DEQs Local Water Supply Planning website, specifically the Durham's 2021 Municipal Local Water Supply Plan (LWSP): 
 * Navigate to https://www.ncwater.org/WUDC/app/LWSP/search.php
 * Scroll down and select the LWSP link next to Durham Municipality. 
 * Note the web address: <https://www.ncwater.org/WUDC/app/LWSP/report.php?pwsid=03-32-010&year=2021>
 
Indicate this website as the as the URL to be scraped. (In other words, read the contents into an `rvest` webpage object.)

```{r set.the.scraping.website}
#2

webpage <- read_html(
  "https://www.ncwater.org/WUDC/app/LWSP/report.php?pwsid=03-32-010&year=2021") 
#fetching contents into webpage object

webpage #viewing object

```

3. The data we want to collect are listed below:

* From the "1. System Information" section:
 * Water system name
 * PSWID
 * Ownership
 
* From the "3. Water Supply Sources" section:
 * Maximum Daily Use (MGD) - for each month

In the code chunk below scrape these values, assigning them to four separate variables.

>HINT: The first value should be "Durham", the second "03-32-010", the third "Municipality", and the last should be a vector of 12 numeric values (represented as strings), with the first value being "27.6400".

```{r scrape.the.data}
#3
water.system.name <- webpage %>%
  html_nodes("div+ table tr:nth-child(1) td:nth-child(2)") %>%
  html_text()
water.system.name

pswid <- webpage %>%
  html_nodes("td tr:nth-child(1) td:nth-child(5)") %>%
  html_text()
pswid

ownership <- webpage %>%
  html_nodes("div+ table tr:nth-child(2) td:nth-child(4)") %>%
  html_text()
ownership
  
max.withdrawals.mgd <- webpage %>%
  html_nodes("th~ td+ td , th~ td+ td") %>%
  html_text()
max.withdrawals.mgd

```


4. Convert your scraped data into a dataframe. This dataframe should have a column for each of the 4 variables scraped and a row for the month corresponding to the withdrawal data. Also add a Date column that includes your month and year in data format. (Feel free to add a Year column too, if you wish.)

>TIP: Use `rep()` to repeat a value when creating a dataframe.

>NOTE: It's likely you won't be able to scrape the monthly widthrawal data in chronological order. You can overcome this by creating a month column manually assigning values in the order the data are scraped: "Jan", "May", "Sept", "Feb", etc...

5. Create a line plot of the maximum daily withdrawals across the months for 2021

```{r create.a.dataframe.from.scraped.data}
#4
max_withdrawals_df <- data.frame(
  "Month"=as.factor(c("Jan", "May", "Sept", "Feb", "Jun",
                      "Oct", "Mar", "Jul", "Nov", 
                      "Apr", "Aug", "Dec")), #creating month vector
  "Year"=as.factor(rep(2021,12)), #repeating 2021 for all 12 values
  "Maximum Daily Withdrawals"=as.numeric(max.withdrawals.mgd))

max_withdrawals_df <- max_withdrawals_df %>%
  mutate("Water System Name"=!!water.system.name,
         "PSWID"=!!pswid,
         "Ownership"=ownership,
         Date = my(paste(Month,"-",Year))) %>%
  #using mutate to create columns retrieving the scraped variables
  arrange(ymd(Date)) #arranging in chronological order

max_withdrawals_df #viewing data frame
 
#5
max_withdrawals_plot <- 
  ggplot(max_withdrawals_df, aes(
    x=Date, y=Maximum.Daily.Withdrawals))+ 
  geom_line() + #creating line plot
  scale_x_date(date_breaks="1 month", labels=date_format("%m-%Y")) +
  #using scale_x_date to make a break for each month in x axis
  theme(axis.text.x=element_text(angle=60, hjust=1)) +
  #tilting the angle of the x axis text
  ylab(expression("Maximum Daily Withdrawals (mgd)")) + 
  #setting y axis label
  xlab(expression("Date")) #setting x axis label
max_withdrawals_plot
```

6. Note that the PWSID and the year appear in the web address for the page we scraped. Construct a function using your code above that can scrape data for any PWSID and year for which the NC DEQ has data. **Be sure to modify the code to reflect the year and site (pwsid) scraped**.

```{r construct.a.scraping.function}
#6.
scrape.it <- function(the_PWSID, the_year){
  
  #retrieve website contents
  webpage <-read_html(paste0(
    'https://www.ncwater.org/WUDC/app/LWSP/report.php?pwsid=', 
    the_PWSID, "&year=", the_year))
  
  #setting element address variables
  the_PWSID_tag <-'td tr:nth-child(1) td:nth-child(5)'
  the_water_name_tag <- 'div+ table tr:nth-child(1) td:nth-child(2)'
  the_ownership_tag <- 'div+ table tr:nth-child(2) td:nth-child(4)'
  the_data_tag <- 'th~ td+ td , th~ td+ td'
  
  #scraping the data items
  the_PWSID <- webpage %>% html_nodes(
    the_PWSID_tag) %>% html_text()
  the_water_name <- webpage %>% html_nodes(
    the_water_name_tag) %>% html_text()
  the_ownership <- webpage %>% html_nodes(
    the_ownership_tag) %>% html_text()
  the_daily_withdrawals <- webpage %>% html_nodes(
    the_data_tag) %>% html_text()
  
  #creating a scraped data frame
  scrape_max_withdrawals_df <- data.frame(
    "Month" = as.factor(c("Jan", "May", "Sept",
                          "Feb", "Jun","Oct", 
                          "Mar", "Jul", "Nov", 
                          "Apr", "Aug", "Dec")),
    "Year" = as.factor(rep(the_year,12)),
    "Maximum Daily Withdrawals"=as.numeric(the_daily_withdrawals))
   
  scrape_max_withdrawals_df <-scrape_max_withdrawals_df %>%
  mutate("PSWID" =!!the_PWSID,
         "Water System Name"=!!the_water_name,
         "Ownership"=!!the_ownership,
         "Date"=my(paste(Month,"-",!!the_year))) %>%
    #using mutate to create columns retrieving the scraped variables
  arrange(ymd(Date)) #arranging in chronological order
}
scrape_max_withdrawals_df <- scrape.it("03-32-010", 2021)
#scraping for Durham PSWID (03-32-010) and 2021 year
scrape_max_withdrawals_df #viewing data frame

```

7. Use the function above to extract and plot max daily withdrawals for Durham (PWSID='03-32-010') for each month in 2015

```{r fetch.and.plot.Durham.2015.data}
#7
#testing the function
dur2015_scrape_max_withdrawals_df <- scrape.it('03-32-010', 2015)
#scraping for Durham PSWID (03-32-010) and 2015 year
dur2015_scrape_max_withdrawals_df #viewing data frame

#plotting
max_withdrawals_2015_plot <- 
  ggplot(dur2015_scrape_max_withdrawals_df, aes(
    x=Date, y=Maximum.Daily.Withdrawals))+ 
  geom_line() + #creating line plot
  scale_x_date(date_breaks="1 month", labels=date_format("%m-%Y")) +
  #using scale_x_date to make a break for each month in x axis
  theme(axis.text.x=element_text(angle=60, hjust=1)) +
  #tilting the angle of the x axis text
  ylab(expression("Maximum Daily Withdrawals (mgd)")) + 
  #setting y axis label
  xlab(expression("Date")) #setting x axis label
max_withdrawals_2015_plot

```

8. Use the function above to extract data for Asheville (PWSID = 01-11-010) in 2015. Combine this data with the Durham data collected above and create a plot that compares Asheville's to Durham's water withdrawals.

```{r fetch.and.plot.Asheville.2015.data}
#8
ash2015_scrape_max_withdrawals_df <- scrape.it('01-11-010', 2015)
#scraping for Asheville PSWID (01-11-010) and 2015 year
ash2015_scrape_max_withdrawals_df #viewing data frame

ash_durham_2015_plot <- ggplot() + 
  geom_line(data=dur2015_scrape_max_withdrawals_df, aes(
    x=Date, y=Maximum.Daily.Withdrawals, color="Durham")) + 
  #creating line plot
  geom_line(data=ash2015_scrape_max_withdrawals_df, aes(
    x=Date, y=Maximum.Daily.Withdrawals, color="Asheville")) + 
  #creating line plot
  scale_x_date(date_breaks="1 month", labels=date_format("%m-%Y")) +
  #using scale_x_date to make a break for each month in x axis
  theme(axis.text.x=element_text(angle=60, hjust=1)) +
  #tilting the angle of the x axis text
  ylab(expression("Maximum Daily Withdrawals (mgd)")) + 
  #setting y axis label
  xlab(expression("Date")) + #setting x axis label
  labs(colour="Water System")
ash_durham_2015_plot

```


9. Use the code & function you created above to plot Asheville's max daily withdrawal by months for the years 2010 thru 2019. Add a smoothed line to the plot.

>TIP: See Section 3.2 in the "09_Data_Scraping.Rmd" where we apply "map2()" to iteratively run a function over two inputs. Pipe the output of the map2() function to `bindrows()` to combine the dataframes into a single one. 

```{r fetch.and.plot.Asheville.multiyear.data}
#9
the_years <- seq(2010,2019) #creating a sequence of years
  
ash_2010_2019_df <- map2("01-11-010",the_years,scrape.it) %>%
  #using map2 to run the function scrape.it with two inputs
  #two inputs are the PSWID and the years
  bind_rows() #binding the data frames to a single one
head(ash_2010_2019_df) #viewing first few rows of the data frame
tail(ash_2010_2019_df) #viewing last few rows of the data frame

ash_2010_2019_plot <- ggplot(ash_2010_2019_df, aes(
    x=Date, y=Maximum.Daily.Withdrawals)) + 
  geom_line() + #creating line plot
  geom_smooth(method=loess, color="blue", se=FALSE) +
  scale_x_date(date_breaks="1 year", labels=date_format("%m-%Y")) +
  #using scale_x_date to make a break for each month in x axis
  theme(axis.text.x=element_text(angle=60, hjust=1)) +
  #tilting the angle of the x axis text
  ylab(expression("Maximum Daily Withdrawals (mgd)")) + 
  #setting y axis label
  xlab(expression("Date")) #setting x axis label
ash_2010_2019_plot

```

>Question: Just by looking at the plot (i.e. not running statistics), does Asheville have a trend in water usage over time?

>ANSWER: Yes, it appears that Asheville has an increase in water usage over time. Particularly, after 2017, it appears that water usage has drastically increased in Asheville. Before 2017, water usage appeared to be relatively constant.

